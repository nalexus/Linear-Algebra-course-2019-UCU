{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 6. Iteration methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \\begin{pmatrix}2&-1&0\\\\ -1&2&-1\\\\ 0&-1&2\\end{pmatrix}; b = \\begin{pmatrix}1\\\\ 0\\\\ 1\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,-1,0], [-1,2,-1],[0,-1,2]])\n",
    "b = np.array([1,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Solve the system using Gaussian elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.linalg.solve(A, b)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Determine the D, L, and U matrices of the Jacobi and Gauss‚ÄìSeidel method and determine the spectral radius of D^-1 (L + U) = B_j and (L + D)^-1 U = B_GS. Comment on whether the Jacobi and Gauss‚ÄìSeidel methods will always converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "L = np.tril(A,-1)\n",
    "# Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "D = np.diag(np.diag(A))\n",
    "# Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "U = np.triu(A,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, -1,  0],\n",
       "       [-1,  0, -1],\n",
       "       [ 0, -1,  0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(L,U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral radius of a matrix is a maximum absolute value of its eigenvalues. Let's find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral radius of B_j is 0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "#let's find spectral radius for D^-1 (L + U) = B_j\n",
    "B_j = np.dot(np.linalg.inv(D),np.add(L,U))\n",
    "print('spectral radius of B_j is',max(abs(np.linalg.eigvals(B_j))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral radius of B_GS is 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "#let's find spectral radius for D^-1 (L + D)^-1 U = B_GS\n",
    "B_GS = np.dot(np.linalg.inv(np.add(L,D)),U)\n",
    "print('spectral radius of B_GS is',max(abs(np.linalg.eigvals(B_GS))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobi and Gauss‚ÄìSeidel methods will always converge because the maximum absolute value of their B_j and B_GS spectral radiuses is less than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Perform 10 steps of the Jacobi method starting with x_0 = (0, 0, 0)^T, and evaluate the Euclidean norm of the difference $x_{k+1}-x_k$ of two successive approximate solutions for k=0,1,...,9. Does the decay rate agree with the predicted one based on the spectral radius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(A,b,x):\n",
    "    \"\"\"Solves equation Ax=b via the Jacobi iterative method\n",
    "    \"\"\"\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    # Calculate matrix B_j\n",
    "    B_j = -np.dot(np.linalg.inv(D),np.add(L,U))\n",
    "    # Calculate vector b_j\n",
    "    b_j = np.dot(np.linalg.inv(D),b)\n",
    "    #create list of solutions with x_0 already present in it , so that we can compare it with x_1 and so on.\n",
    "    list_solutions=[x]\n",
    "    #calculating x_1\n",
    "    x = np.add(np.dot(B_j,x),b_j)\n",
    "    #adding x_1 to list of solutions\n",
    "    list_solutions.append(x)\n",
    "    #calculating first norm difference x_{k+1}-x_k\n",
    "    norm_differences=[np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2]))]\n",
    "    #creating list of decay rates (ratios)\n",
    "    ratios = []\n",
    "    # Calculate next values\n",
    "    for i in range(2,10):\n",
    "        x = np.add(np.dot(B_j,x),b_j)\n",
    "        list_solutions.append(x)\n",
    "        ratios.append((np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))/(np.linalg.norm(np.subtract(list_solutions[-2],list_solutions[-3]))))\n",
    "        norm_differences.append(np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))\n",
    "    return ratios,norm_differences\n",
    "    #print('Norm of difference between two successive solutions: ',np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratios,norm_differences = jacobi(A,b,x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean norm of the difference $x_{k+1}-x_k$ of two successive approximate solutions for k=0,1,...,9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865476\n",
      "0.5\n",
      "0.3535533905932738\n",
      "0.25\n",
      "0.1767766952966369\n",
      "0.125\n",
      "0.08838834764831845\n",
      "0.0625\n",
      "0.04419417382415922\n"
     ]
    }
   ],
   "source": [
    "for i in norm_differences:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that norm differences are decreasing, which means that we are converging to solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the decay rate agree with the predicted one based on the spectral radius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067811865475\n",
      "0.7071067811865476\n",
      "0.7071067811865475\n",
      "0.7071067811865476\n",
      "0.7071067811865475\n",
      "0.7071067811865476\n",
      "0.7071067811865475\n",
      "0.7071067811865476\n"
     ]
    }
   ],
   "source": [
    "for i in ratios:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our predicted decay rate, based on spectral radius, is 0.7071067, we see that all 8 decay rates (ratios computed from $\\frac{||x_{k+1} - x_{k}||}{||x_{k} - x_{k-1}||}$) are exactly equal to our predicted rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Perform 10 steps of the Gauss-Seidel method starting with x_0 = (0, 0, 0)^T, and evaluate the Euclidean norm of the difference $x_{k+1}-x_k$ of two successive approximate solutions for k=0,1,...,9. Does the decay rate agree with the predicted one based on the spectral radius?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will exactly do the same as in (c):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A,b,x):\n",
    "    \"\"\"Solves equation Ax=b via the Jacobi iterative method\n",
    "    \"\"\"\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    #adding x_0 to list of solutions\n",
    "    list_solutions=[x]\n",
    "    #calculating x_1\n",
    "    B_GS_times_x = np.dot(np.dot(-(np.linalg.inv(np.add(L,D))),U),x)\n",
    "    b_GS = np.dot(np.linalg.inv(np.add(L,D)),b)\n",
    "    x = np.add(B_GS_times_x,b_GS)\n",
    "    #adding x_1 to list of solutions\n",
    "    list_solutions.append(x)\n",
    "    #calculating first norm difference x_{k+1}-x_k\n",
    "    norm_differences=[np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2]))]\n",
    "    #creating list of decay rates (ratios)\n",
    "    ratios = []\n",
    "    # Calculate next values\n",
    "    for i in range(2,10):\n",
    "        B_GS_times_x = np.dot(np.dot(-(np.linalg.inv(np.add(L,D))),U),x)\n",
    "        b_GS = np.dot(np.linalg.inv(np.add(L,D)),b)\n",
    "        x = np.add(B_GS_times_x,b_GS)\n",
    "        list_solutions.append(x)\n",
    "        ratios.append((np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))/(np.linalg.norm(np.subtract(list_solutions[-2],list_solutions[-3]))))\n",
    "        norm_differences.append(np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))\n",
    "    return ratios,norm_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios,norm_differences = gauss_seidel(A,b,x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean norm of the difference $x_{k+1}-x_k$ of two successive approximate solutions for k=0,1,...,9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8385254915624212\n",
      "0.4375\n",
      "0.28125\n",
      "0.140625\n",
      "0.0703125\n",
      "0.03515625\n",
      "0.017578125\n",
      "0.0087890625\n",
      "0.00439453125\n"
     ]
    }
   ],
   "source": [
    "for i in norm_differences:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that norm differences are decreasing, which means that we are converging to solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the decay rate agree with the predicted one based on the spectral radius?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5217491947499509\n",
      "0.6428571428571429\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "for i in ratios:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that our predicted decay rate, based on spectral radius, is 0.4999999, we see that last 6 decay rates (ratios computed from $\\frac{||x_{k+1} - x_{k}||}{||x_{k} - x_{k-1}||}$) are approximately equal to our predicted rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e)  Perform 10 steps of the SOR method using œâ = 0.1 and then œâ = 1.1 starting with x_0 = (0, 0, 0)^T, and evaluate the Euclidean norm of the difference $x_{k+1}-x_k$ of two successive approximate solutions for k=0,1,...,9. Does the decay rate agree with the predicted one based on the spectral radius?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral radius of SOR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,-1,0], [-1,2,-1],[0,-1,2]])\n",
    "L = np.tril(A,-1)\n",
    "# Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "D = np.diag(np.diag(A))\n",
    "# Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "U = np.triu(A,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral radius of B_GS is for œâ=0.1: 0.9696286079104867\n"
     ]
    }
   ],
   "source": [
    "print('spectral radius of B_GS is for œâ=0.1:',max(abs(np.linalg.eigvals((np.dot((np.linalg.inv(np.add(D,0.1*L))),(np.subtract(((1 - 0.1)*D),(0.1*U)))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectral radius of B_GS is for œâ=1.1: 0.3785859165294031\n"
     ]
    }
   ],
   "source": [
    "print('spectral radius of B_GS is for œâ=1.1:',max(abs(np.linalg.eigvals((np.dot((np.linalg.inv(np.add(D,1.1*L))),(np.subtract(((1 - 1.1)*D),(1.1*U)))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(A,b,x,œâ):\n",
    "    \"\"\"Solves equation Ax=b via the Jacobi iterative method\n",
    "    \"\"\"\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    #adding x_0 to list of solutions\n",
    "    list_solutions=[x]\n",
    "    #calculating x_1\n",
    "    B_SOR_times_x = np.dot((np.dot((np.linalg.inv(np.add(D,œâ*L))),(np.subtract(((1 - œâ)*D),(œâ*U))))),(x))\n",
    "    b_SOR = œâ*np.dot(np.linalg.inv(np.add(D,œâ*L)),b)\n",
    "    x = np.add(B_SOR_times_x,b_SOR)\n",
    "    #adding x_1 to list of solutions\n",
    "    list_solutions.append(x)\n",
    "    #calculating first norm difference x_{k+1}-x_k\n",
    "    norm_differences=[np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2]))]\n",
    "    #creating list of decay rates (ratios)\n",
    "    ratios = []\n",
    "    # Calculate next values\n",
    "    for i in range(2,10):\n",
    "        B_SOR_times_x = np.dot((np.dot((np.linalg.inv(np.add(D,œâ*L))),(np.subtract(((1 - œâ)*D),(œâ*U))))),(x))\n",
    "        b_SOR = œâ*np.dot(np.linalg.inv(np.add(D,œâ*L)),b)\n",
    "        x = np.add(B_SOR_times_x,b_SOR)\n",
    "        list_solutions.append(x)\n",
    "        ratios.append((np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))/(np.linalg.norm(np.subtract(list_solutions[-2],list_solutions[-3]))))\n",
    "        norm_differences.append(np.linalg.norm(np.subtract(list_solutions[-1],list_solutions[-2])))\n",
    "    return ratios,norm_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios_w01,norm_differences_w01 = SOR(A,b,x_0,0.1)\n",
    "ratios_w11,norm_differences_w11 = SOR(A,b,x_0,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For œâ = 0.1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08381163776588547\n",
      "0.07039851361456877\n",
      "0.05924237680859251\n",
      "0.0499759345835764\n",
      "0.042292313980117915\n",
      "0.03593486138373003\n",
      "0.030688535124398283\n",
      "0.026372635347273254\n",
      "0.022834683943908213\n"
     ]
    }
   ],
   "source": [
    "for i in norm_differences_w01:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that norm differences are decreasing, which means that we are converging to solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8399610780929476\n",
      "0.8415288017719237\n",
      "0.8435842259510408\n",
      "0.8462535885025039\n",
      "0.8496782985348924\n",
      "0.8540045499742184\n",
      "0.8593644251955916\n",
      "0.8658476349906821\n"
     ]
    }
   ],
   "source": [
    "for i in ratios_w01:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ratio value is slowly approaching spectral radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For œâ = 1.1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7314702766517585\n",
      "0.24450708390252343\n",
      "0.12162261750143513\n",
      "0.0352768844865472\n",
      "0.014441195749375142\n",
      "0.005358200695882537\n",
      "0.002039436865611563\n",
      "0.0007710121300492318\n",
      "0.0002920033236505023\n"
     ]
    }
   ],
   "source": [
    "for i in norm_differences_w11:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that norm differences are decreasing, which means that we are converging to solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3342679691945014\n",
      "0.49741960666432833\n",
      "0.2900520085101025\n",
      "0.40936709575025754\n",
      "0.37103580540512937\n",
      "0.38061972318034865\n",
      "0.3780514822742647\n",
      "0.3787272758365771\n"
     ]
    }
   ],
   "source": [
    "for i in ratios_w11:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ratio value is very close to the spectral radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \\alpha I + u u^\\top, u = (1,-1,1)^\\top \n",
    "\\rightarrow \\\\\n",
    "\\rightarrow \n",
    "u u^\\top:\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1  1]\n",
      " [-1  1 -1]\n",
      " [ 1 -1  1]]\n"
     ]
    }
   ],
   "source": [
    "u = np.array([1,-1,1])\n",
    "uuT = np.outer(u,u)\n",
    "print(uuT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\rightarrow\n",
    "u u^\\top = \n",
    "\\begin{pmatrix}1&-1&1\\\\ -1&1&-1\\\\ 1&-1&1\\end{pmatrix}\n",
    "\\rightarrow\n",
    "\\\\\n",
    "\\rightarrow\n",
    "A = \n",
    "\\begin{pmatrix}Œ±&0&0\\\\ 0&Œ±&0\\\\ 0&0&Œ±\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}1&-1&1\\\\ -1&1&-1\\\\ 1&-1&1\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1\\\\ -1&Œ±+1&-1\\\\ 1&-1&Œ±+1\\end{pmatrix}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b = u =\n",
    "\\begin{pmatrix}1\\\\ -1\\\\ 1\\end{pmatrix}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Ax = b\n",
    "\\rightarrow\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ -1&Œ±+1&-1&-1\\\\ 1&-1&Œ±+1&1\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Find a closed form solution (if any) for each real $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ -1&Œ±+1&-1&-1\\\\ 1&-1&Œ±+1&1\\end{pmatrix}\n",
    "R_2\\:\\leftarrow \\:R_2+\\frac{1}{Œ±+1}\\cdot \\:R_1\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&\\frac{Œ±^2+2Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}\\\\ 1&-1&Œ±+1&1\\end{pmatrix}\n",
    "R_3\\:\\leftarrow \\:R_3-\\frac{1}{Œ±+1}\\cdot \\:R_1\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&\\frac{Œ±^2+2Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}\\\\ 0&-\\frac{Œ±}{Œ±+1}&\\frac{Œ±^2+2Œ±}{Œ±+1}&\\frac{Œ±}{Œ±+1}\\end{pmatrix}\n",
    "\\:R_2\\:\\leftrightarrow \\:R_3\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&-\\frac{Œ±}{Œ±+1}&\\frac{Œ±^2+2Œ±}{Œ±+1}&\\frac{Œ±}{Œ±+1}\\\\ 0&\\frac{Œ±^2+2Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}&-\\frac{Œ±}{Œ±+1}\\end{pmatrix}\n",
    "R_3\\:\\leftarrow \\:R_3-\\left(-Œ±-2\\right)\\cdot \\:R_2\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&-\\frac{Œ±}{Œ±+1}&\\frac{Œ±^2+2Œ±}{Œ±+1}&\\frac{Œ±}{Œ±+1}\\\\ 0&0&Œ±\\left(Œ±+3\\right)&Œ±\\end{pmatrix}\n",
    "R_3\\:\\leftarrow \\frac{1}{Œ±\\left(Œ±+3\\right)}\\cdot \\:R_3\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&-\\frac{Œ±}{Œ±+1}&\\frac{Œ±^2+2Œ±}{Œ±+1}&\\frac{Œ±}{Œ±+1}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "R_2\\:\\leftarrow \\:R_2-\\frac{Œ±^2+2Œ±}{Œ±+1}\\cdot \\:R_3\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1&1\\\\ 0&-\\frac{Œ±}{Œ±+1}&0&\\frac{Œ±}{\\left(Œ±+1\\right)\\left(Œ±+3\\right)}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "\\:R_1\\:\\leftarrow \\:R_1-1\\cdot \\:R_3\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&0&\\frac{Œ±+2}{Œ±+3}\\\\ 0&-\\frac{Œ±}{Œ±+1}&0&\\frac{Œ±}{\\left(Œ±+1\\right)\\left(Œ±+3\\right)}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "R_2\\:\\leftarrow \\:-\\frac{Œ±+1}{Œ±}\\cdot \\:R_2\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&0&\\frac{Œ±+2}{Œ±+3}\\\\ 0&1&0&-\\frac{1}{Œ±+3}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "\\:R_1\\:\\leftarrow \\:R_1+1\\cdot \\:R_2\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&0&0&\\frac{Œ±+1}{Œ±+3}\\\\ 0&1&0&-\\frac{1}{Œ±+3}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "R_1\\:\\leftarrow \\frac{1}{Œ±+1}\\cdot \\:R_1\n",
    "=\n",
    "\\begin{pmatrix}1&0&0&\\frac{1}{Œ±+3}\\\\ 0&1&0&-\\frac{1}{Œ±+3}\\\\ 0&0&1&\\frac{1}{Œ±+3}\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:\n",
    "\n",
    "We see that $\\alpha$ $\\in$ $\\mathbb{R}$ in ${(-\\infty,-3)\\cup(-3,\\infty)}$. That's because we can't divide by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) For what ùõº do the methods work? Justify your answer by referring to the spectral radius or the norm of the corresponding B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not told whether to check necessary or sufficient conditions, we will check sufficient for Jacobi and necessary for Gauss-Seidel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.1 Jacobi:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that sufficient condition for Jacobi methods to converge is that corresponding iteration matrix $Bj$ norm being less than 1: \n",
    "\n",
    "$|| Bj || < 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see for what $\\alpha$ we have $|| Bj ||_{\\infty} < 1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "Bj\n",
    "=\n",
    "-D^{-1}(L+U)\n",
    "=\n",
    "-\\begin{pmatrix}\\frac{1}{Œ±+1}&0&0\\\\ \\:\\:\\:0&\\frac{1}{Œ±+1}&0\\\\ \\:\\:\\:0&0&\\frac{1}{Œ±+1}\\end{pmatrix}\\begin{pmatrix}0&-1&1\\\\ \\:\\:\\:-1&0&-1\\\\ \\:\\:\\:1&-1&0\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}0&\\frac{1}{Œ±+1}&-\\frac{1}{Œ±+1}\\\\ \\frac{1}{Œ±+1}&0&\\frac{1}{Œ±+1}\\\\ -\\frac{1}{Œ±+1}&\\frac{1}{Œ±+1}&0\\end{pmatrix}\n",
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$|| Bj ||_{\\infty} = \\max{\\sum_{j=1}^{n}| a_{ij} |}$ = $|-\\frac{2}{\\alpha+1}| \\rightarrow$\n",
    "\n",
    "So, given denominator of $|| Bj ||_{\\infty}$, in order for $|| Bj ||_{\\infty} <1$ we need :\n",
    "\n",
    "$\\rightarrow \\alpha \\in \\mathbb{R}$ in ${(-\\infty,-3)\\cup(1,\\infty)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.2 Gauss-Seidel:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that necessary condition for Gauss-Seidel is that spectral radius $p(B_{GS})<1$. We also know from the lecture that spectral radius $p(B_{GS})<1$ if $A$ is row diagonally dominant. \n",
    "\n",
    "So, let's check whether A is strictly row diagonally dominant:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Square matrix A is strictly diagonally dominant if, for every row of the matrix, the magnitude of the diagonal entry in a row is larger than sum of the magnitudes of all non-diagonal entries in that row:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "| a_{i,i} | > \\sum _{j\\not=i}\\:| a_{i,i} | \n",
    "$$\n",
    "for all $i$, where $a_{ij}$ denotes the entry in the ith row and jth column.\n",
    "Thus, let's solve for $\\alpha$ for every row:\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "Row 1 : \n",
    "$$\n",
    "\\\\\n",
    "| a_{1,1} | = | \\alpha +1 |; | a_{1,2} | + | a_{1,3} | = 2\n",
    "\\rightarrow\n",
    "\\\\\n",
    "\\rightarrow \n",
    "| \\alpha + 1 | > 2\n",
    "\\rightarrow\n",
    "\\alpha+1<-2\\quad \\mathrm{or}\\quad \\:\\alpha+1>2\n",
    "\\rightarrow\n",
    "\\\\\n",
    "\\rightarrow\n",
    "\\alpha<-3\\quad \\mathrm{or}\\quad \\:\\alpha>1.\n",
    "$$\n",
    "$$\n",
    "\\\\\n",
    "$$\n",
    "We can clearly see that the same inequality holds also for all other rows: row 2 and row 3.\n",
    "$$\n",
    "$$\n",
    "Thus, Gauss-Seidel and SOR methods necessary condition for Gauss-Seidel convergence is satisfied when $ \\alpha \\in \\mathbb{R}$ in ${(-\\infty,-3)\\cup(1,\\infty)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Write the corresponding iteration scheme for Jacobi method starting with $x_0=$*0*. How many iterations are required to achieve 0.001 accuracy? Test three different Œ± in the convergence range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check in convergence range for $\\alpha > 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the next formula for measuring accuracy of current iteration in order to check whether we reached stopping criteria $\\epsilon$ (which in our case equals 0.001):\n",
    "$$\n",
    "\\frac{| x_{k}-x_{k-1}  |}{| x_{k} |} < \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "#let's firstly create 'b' vector from Ax=b\n",
    "b = np.array([1,-1,1])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi(ùõº,uuT,b,stopping_criteria=0.001):\n",
    "    \"\"\"Solves equation Ax=b via the Jacobi iterative method,where\n",
    "    ùõº - parameter alpha of Problem 2 (;\n",
    "    uuT - outer product of u;\n",
    "    Instruction:\n",
    "    we will perform first iteration and other iterations separately,\n",
    "    because we can't divide by the norm of x_0 as it is a zero vector. Other \n",
    "    iterations will be perform via 'while' loop using base case accuracy of 10.\n",
    "    \"\"\"\n",
    "    # Create matrix A from sum of matrix ùõºI and matrix uu^T (ùõºI + uu^T)\n",
    "    alpha_times_identity = np.array([[Œ±,0,0],[0,Œ±,0],[0,0,Œ±]])\n",
    "    A = np.add(alpha_times_identity,uuT)\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    # Calculate matrix B_j\n",
    "    B_j = -np.dot(np.linalg.inv(D),np.add(L,U))\n",
    "    # Calculate vector b_j\n",
    "    b_j = np.dot(np.linalg.inv(D),b)\n",
    "    #initial guess\n",
    "    x = np.zeros(3)\n",
    "    #first iteration\n",
    "    x = np.add(np.dot(B_j,x),b_j)\n",
    "    #creating a list to count lately the number of iterations before reaching a stopping criteria\n",
    "    list_1=[]\n",
    "    list_1.append(x)\n",
    "    #establish a base case accuracy\n",
    "    acc=10\n",
    "    #second and other iterations\n",
    "    while acc >= stopping_criteria:\n",
    "        #formula for checking out current accuracy: np.linalg.norm(np.add(np.dot(B_j,x),b_j)-x)/np.linalg.norm(x)\n",
    "        acc = np.linalg.norm(np.add(np.dot(B_j,x),b_j)-x)/np.linalg.norm(x)\n",
    "        x = np.add(np.dot(B_j,x),b_j)\n",
    "        list_1.append(x)\n",
    "    num_iter = len(list_1)\n",
    "    print('Number of iteration to achieve 0.001 accuracy: ', num_iter)\n",
    "    print('Found solution is vector: ', x)\n",
    "    return x, num_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how many iterations are required to achieve 0.001 accuracy for such choice of ùõº as (2,3,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Alpha coefficient:  2\n",
      "Number of iteration to achieve 0.001 accuracy:  20\n",
      "Found solution is vector:  [ 0.19993985 -0.19993985  0.19993985]\n",
      "\n",
      "For Alpha coefficient:  3\n",
      "Number of iteration to achieve 0.001 accuracy:  12\n",
      "Found solution is vector:  [ 0.16662598 -0.16662598  0.16662598]\n",
      "\n",
      "For Alpha coefficient:  4\n",
      "Number of iteration to achieve 0.001 accuracy:  9\n",
      "Found solution is vector:  [ 0.14289459 -0.14289459  0.14289459]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ùõº in (2,3,4):\n",
    "    print('For Alpha coefficient: ', ùõº)\n",
    "    x, num_iter = jacobi(ùõº,uuT,b)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Write the corresponding iteration scheme for Gauss-Seidel method starting with $x_0=$*0*. How many iterations are required to achieve 0.001 accuracy? Test three different Œ± in the convergence range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same convergence range ($\\alpha>1$) for Gauss-Seidel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(ùõº,uuT,b,stopping_criteria=0.001):\n",
    "    \"\"\"Solves equation Ax=b via the Gauss-Seidel iterative method,where\n",
    "    ùõº - parameter alpha of Problem 2 (;\n",
    "    uuT - outer product of u;\n",
    "    Instruction:\n",
    "    we will perform first iteration and other iterations separately,\n",
    "    because we can't divide by the norm of x_0 as it is a zero vector. Other \n",
    "    iterations will be perform via 'while' loop using base case accuracy of 10.\n",
    "    \"\"\"\n",
    "    # Create matrix A from sum of matrix ùõºI and matrix uu^T (ùõºI + uu^T)\n",
    "    alpha_times_identity = np.array([[Œ±,0,0],[0,Œ±,0],[0,0,Œ±]])\n",
    "    A = np.add(alpha_times_identity,uuT)\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    #initial guess\n",
    "    x = np.zeros(3)\n",
    "    #First iteration\n",
    "    B_GS_times_x = np.dot(np.dot(-(np.linalg.inv(np.add(L,D))),U),x)\n",
    "    b_GS = np.dot(np.linalg.inv(np.add(L,D)),b)\n",
    "    x = np.add(B_GS_times_x,b_GS)\n",
    "    #creating a list to count lately the number of iterations before reaching a stopping criteria\n",
    "    list_1=[]\n",
    "    list_1.append(x)\n",
    "    #establish a base case accuracy\n",
    "    acc=10\n",
    "    #second and other iterations\n",
    "    while acc >= stopping_criteria:\n",
    "        #formula for checking out current accuracy: np.linalg.norm(np.add(np.dot(B_j,x),b_j)-x)/np.linalg.norm(x)\n",
    "        #in function np.add we put values for formula B_GS+b_GS as np.add(B_GS,b_GS) \n",
    "        acc = np.linalg.norm(np.add(np.dot(np.dot(-(np.linalg.inv(np.add(L,D))),U),x),np.dot(np.linalg.inv(np.add(L,D)),b))-x)/np.linalg.norm(x)\n",
    "        x = np.add(np.dot(np.dot(-(np.linalg.inv(np.add(L,D))),U),x),np.dot(np.linalg.inv(np.add(L,D)),b))\n",
    "        list_1.append(x)\n",
    "    num_iter = len(list_1)\n",
    "    print('Number of iteration to achieve 0.001 accuracy: ', num_iter)\n",
    "    print('Found solution is vector: ', x)\n",
    "    return x, num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Alpha coefficient:  2\n",
      "Number of iteration to achieve 0.001 accuracy:  6\n",
      "Found solution is vector:  [ 0.19997326 -0.1999872   0.20001318]\n",
      "\n",
      "For Alpha coefficient:  3\n",
      "Number of iteration to achieve 0.001 accuracy:  5\n",
      "Found solution is vector:  [ 0.16664816 -0.16666032  0.16667288]\n",
      "\n",
      "For Alpha coefficient:  4\n",
      "Number of iteration to achieve 0.001 accuracy:  5\n",
      "Found solution is vector:  [ 0.14285524 -0.14285533  0.14285788]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ùõº in (2,3,4):\n",
    "    print('For Alpha coefficient: ', ùõº)\n",
    "    gauss_seidel(ùõº,uuT,b)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Write the corresponding iteration scheme for SOR using œâ = 0.1 and œâ = 1.1  method with $x_0=$*0*. How many iterations are required to achieve 0.001 accuracy? Test three different Œ± in the convergence range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will show that we can use the same convergence range for SOR as in (c) and (d). In (b) we established only convergence for Jacobi and Gauss-Seidel methods. But here in SOR we don't need to refer to spectral radius or norm. If A is symmetric and positive definite, then the SOR method is convergent iff 0 < œâ < 2. Our œâ is in this interval. A is symmetric. Let's check for which $\\alpha$ A is positive definite. In our case we clearly see from:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "A\n",
    "=\n",
    "\\begin{pmatrix}Œ±+1&-1&1\\\\ -1&Œ±+1&-1\\\\ 1&-1&Œ±+1\\end{pmatrix}\\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that principal minors $D1$ and $D2$ are both $>0$ for $\\alpha>1$. For $D3>0$ we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\det \\begin{pmatrix}Œ±+1&-1&1\\\\ -1&Œ±+1&-1\\\\ 1&-1&Œ±+1\\end{pmatrix}=Œ±^3+3Œ±^2\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, also $D3>0$ for $\\alpha>1$. So we can use the same convergence range for SOR ($\\alpha>1$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(œâ,ùõº,uuT,b,stopping_criteria=0.001):\n",
    "    \"\"\"Solves equation Ax=b via the Gauss-Seidel iterative method,where\n",
    "    ùõº - parameter alpha of Problem 2 (;\n",
    "    uuT - outer product of u;\n",
    "    Instruction:\n",
    "    we will perform first iteration and other iterations separately,\n",
    "    because we can't divide by the norm of x_0 as it is a zero vector. Other \n",
    "    iterations will be perform via 'while' loop using base case accuracy of 10.\n",
    "    \"\"\"\n",
    "    print('œâ is',œâ)\n",
    "    # Create matrix A from sum of matrix ùõºI and matrix uu^T (ùõºI + uu^T)\n",
    "    alpha_times_identity = np.array([[Œ±,0,0],[0,Œ±,0],[0,0,Œ±]])\n",
    "    A = np.add(alpha_times_identity,uuT)\n",
    "    # Create lower-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    L = np.tril(A,-1)\n",
    "    # Create diagonal  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    D = np.diag(np.diag(A))\n",
    "    # Create upper-triangular  matrix from A                                                                                                                                                                                                                                                                                                                     \n",
    "    U = np.triu(A,1)\n",
    "    #function definions of B_SOR * x and b_SOR to use in iterations:\n",
    "    def B_SOR_times_x():\n",
    "        return np.dot((np.dot((np.linalg.inv(np.add(D,œâ*L))),(np.subtract(((1 - œâ)*D),(œâ*U))))),(x))\n",
    "    def b_SOR():\n",
    "        return œâ*np.dot(np.linalg.inv(np.add(D,œâ*L)),b)\n",
    "    #initial guess\n",
    "    x = np.zeros(3)\n",
    "    #First iteration\n",
    "    x = np.add(B_SOR_times_x(),b_SOR())\n",
    "    #creating a list to count lately the number of iterations before reaching a stopping criteria\n",
    "    list_1=[]\n",
    "    list_1.append(x)\n",
    "    #establish a base case accuracy\n",
    "    acc=10\n",
    "    #second and other iterations\n",
    "    while acc >= stopping_criteria:\n",
    "        #formula for checking out current accuracy: np.linalg.norm(np.add(np.dot(B_SOR,x),b_SOR)-x)/np.linalg.norm(x)\n",
    "        #in function np.add we put values for formula B_SOR+b_SOR as np.add(B_GS,b_GS) \n",
    "        acc = np.linalg.norm(np.add(B_SOR_times_x(),b_SOR())-x)/np.linalg.norm(x)\n",
    "        x = np.add(B_SOR_times_x(),b_SOR())\n",
    "        list_1.append(x)\n",
    "    num_iter = len(list_1)\n",
    "    print('Number of iteration to achieve 0.001 accuracy: ', num_iter)\n",
    "    print('Found solution is vector: ', x)\n",
    "    return x, num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For œâ coefficient:  0.1\n",
      "For Alpha coefficient:  2\n",
      "œâ is 0.1\n",
      "Number of iteration to achieve 0.001 accuracy:  31\n",
      "Found solution is vector:  [ 0.20042935 -0.19916538  0.19787467]\n",
      "For Alpha coefficient:  3\n",
      "œâ is 0.1\n",
      "Number of iteration to achieve 0.001 accuracy:  33\n",
      "Found solution is vector:  [ 0.16637071 -0.16577716  0.16517074]\n",
      "For Alpha coefficient:  4\n",
      "œâ is 0.1\n",
      "Number of iteration to achieve 0.001 accuracy:  35\n",
      "Found solution is vector:  [ 0.14237259 -0.14204831  0.14171727]\n",
      "\n",
      "For œâ coefficient:  1.1\n",
      "For Alpha coefficient:  2\n",
      "œâ is 1.1\n",
      "Number of iteration to achieve 0.001 accuracy:  6\n",
      "Found solution is vector:  [ 0.20002803 -0.20002751  0.19998824]\n",
      "For Alpha coefficient:  3\n",
      "œâ is 1.1\n",
      "Number of iteration to achieve 0.001 accuracy:  6\n",
      "Found solution is vector:  [ 0.16665453 -0.16666676  0.16667026]\n",
      "For Alpha coefficient:  4\n",
      "œâ is 1.1\n",
      "Number of iteration to achieve 0.001 accuracy:  6\n",
      "Found solution is vector:  [ 0.14285582 -0.14285454  0.14285712]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for œâ in (0.1,1.1):\n",
    "    print('For œâ coefficient: ', œâ)\n",
    "    for ùõº in (2,3,4):\n",
    "        print('For Alpha coefficient: ', ùõº)\n",
    "        SOR(œâ,ùõº,uuT,b)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Realize the power method to find the dominating eigenvalue of A and the corresponding eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\lambda_1$ is an eigenvalue of $A$  that is larger in absolute value than any  other eigenvalue, it is called the dominant eigenvalue. An eigenvector $v_1$ corresponding to $\\lambda_1$ is called a dominant eigenvector.\n",
    "if $A$ is an $n√ón$ matrix with $n$ distinct eigenvalues $Œª1,Œª2,...,Œªn$ for which one is dominating, say $Œª_1$ such that $‚à£Œª1‚à£>‚à£Œª2‚à£>...>‚à£Œªn‚à£$, then we could approximate the eigenvalue $Œª_1$ iteratively.Formula for matrix $A$:\n",
    "$$\n",
    "x=x_0=some-non-zero-vector.\\\\\n",
    "while:\\\\ \n",
    "epsilon < convergence-criteria:\\\\\n",
    "    p = A x;\\\\\n",
    "    max-entry-of-p = max(map(abs, p));\\\\\n",
    "    x = \\frac{p}{max-entry};\n",
    "$$ \n",
    "From Youssef Saad's book Numerical Methods for Large Eigenvalue Problems, 2nd edition we can use the norm of the residual vector r to define convergence criteria of power method:\n",
    "$$\n",
    "r = |Ax -\\lambda x|\\\\\n",
    "‚Äñr‚Äñ<ùúÄ\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "#Diagonal matrix D\n",
    "D = np.diagflat([[1,2], [3,4],[5,6],[7,8],[9,10]])\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  0  3  3  7  9  3  5  2  4]\n",
      " [ 7  6  8  8 10  1  6  7  7  8]\n",
      " [ 1  5  9  8  9  4  3  0  3  5]\n",
      " [ 0  2  3  8  1  3  3  3  7  0]\n",
      " [ 1  9  9  0 10  4  7  3  2  7]\n",
      " [ 2  0  0  4  5  5  6  8  4  1]\n",
      " [ 4  9 10 10  8  1  1  7  9  9]\n",
      " [ 3  6  7  2  0  3  5  9 10  4]\n",
      " [ 4  6  4  4  3  4  4  8  4  3]\n",
      " [10  7  5  5  0  1  5  9  3  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexus/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: This function is deprecated. Please call randint(0, 10 + 1) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#seed to get reproducable results for random matrix generation\n",
    "np.random.seed(0)\n",
    "#let's constrain our random metrix P entries to range(0,10)\n",
    "P = np.random.random_integers(0, 10, (10,10))\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15033915  0.02591513 -0.20908849  0.15042663  0.1070685  -0.09673381\n",
      "   0.06265476 -0.07786602 -0.22280322  0.12365779]\n",
      " [ 0.07266546 -0.094607   -0.31374845  0.27212391  0.24737708 -0.09614919\n",
      "   0.15274493 -0.1873245  -0.0753201   0.08098657]\n",
      " [-0.08590151 -0.11048329  0.36153976 -0.29976706 -0.1467455   0.15290501\n",
      "  -0.01845919  0.2143909  -0.13244793  0.06427421]\n",
      " [-0.11296805  0.16679967  0.2167197  -0.06137479 -0.21002996 -0.08980167\n",
      "  -0.19507281  0.00149386  0.44785589 -0.14454577]\n",
      " [ 0.13977865 -0.29066834 -0.30666424  0.15602697  0.32339227  0.26258918\n",
      "   0.4066025  -0.15467492 -0.75583487  0.26548329]\n",
      " [ 0.11232458 -0.02987543 -0.04131403  0.09875621  0.02596522 -0.10438845\n",
      "  -0.03601865 -0.02322913  0.11199718 -0.03625959]\n",
      " [-0.13625145  0.30248293  0.18210609 -0.0399124  -0.14277444 -0.13471498\n",
      "  -0.37401335  0.07288839  0.47443819 -0.18263895]\n",
      " [-0.11084712 -0.1019352   0.19640829 -0.27886686 -0.13466767  0.22221575\n",
      "   0.04711096  0.10202589  0.05506144  0.00468426]\n",
      " [ 0.18295162 -0.14786886 -0.41368811  0.33572769  0.29382292  0.0342958\n",
      "   0.28466155 -0.0829793  -0.60050267  0.16838999]\n",
      " [-0.13684302  0.47574934  0.28203913 -0.20177156 -0.36210829 -0.34494865\n",
      "  -0.46939134  0.11765662  0.9882613  -0.43045136]]\n"
     ]
    }
   ],
   "source": [
    "#Let's find inverse of P:\n",
    "P_inverse = np.linalg.inv(P)\n",
    "print(P_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.10498837   7.99322492   7.36058448  -5.90908672  -8.16536431\n",
      "   -3.75250514  -9.52923944   3.71444802  23.54891433 -11.03897697]\n",
      " [ -7.44086383  22.75956395   9.95038736  -8.72978804 -14.19517672\n",
      "   -7.18093568 -16.9877912    7.48670404  35.80849474 -19.42488941]\n",
      " [ -0.83523337  13.78444953   5.31520881   0.34323417  -6.09688943\n",
      "   -9.64271391 -11.35594456   1.54042225  21.61734837 -11.69147534]\n",
      " [  4.62764694  -3.43632917 -10.86740342  12.60422522   7.31273194\n",
      "    2.21664733   6.79725405  -1.21189372 -15.47213992   3.83726709]\n",
      " [ -6.79883565  23.10554641  13.51361482  -9.6029783  -12.89623314\n",
      "  -11.87178473 -23.15013389   6.81009061  42.67971884 -20.21670705]\n",
      " [ -2.24155572   0.17229852   2.28951693  -3.27310079  -1.94129418\n",
      "    8.15172261  -1.05090905   3.08470344   2.89898483  -2.12963924]\n",
      " [ -3.57932858  17.20130885   4.66509305  -5.97587812 -12.16192018\n",
      "   -8.01164241  -8.47618682   6.57324567  28.83972021 -17.61662777]\n",
      " [ -1.12069953   6.38829633  -1.24506117  -0.62244533  -3.73823735\n",
      "   -0.25720658  -3.4302498    8.74962887   7.30011135  -7.23451978]\n",
      " [ -5.00078404   6.12920699   8.85065979  -8.93342991  -9.15261594\n",
      "    1.6268004   -7.31572364   6.27258714  19.96961888  -8.62855157]\n",
      " [ -8.16332819  -0.31074629  12.37177416 -12.22816327  -8.47198513\n",
      "    9.7682802   -3.6420955    7.36167929   8.71605675  -1.28253674]]\n"
     ]
    }
   ],
   "source": [
    "# setting A = P DP^‚àí1\n",
    "A = np.dot(P,np.dot(D,P_inverse))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs,_ = np.linalg.eig(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 10.,  9.,  2.,  3.,  8.,  4.,  7.,  5.,  6.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at eigenvalues\n",
    "eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_method(A,shape=2,epsilon=0.001):\n",
    "    #generate non-zero vector x with 1 at 1st row 1st col to use it in iteration:\n",
    "    x = list(np.zeros(shape))\n",
    "    x[0] = 1\n",
    "    x = np.array(x)\n",
    "    list_max_entries = []\n",
    "    #first iteration\n",
    "    p = np.dot(A,x)\n",
    "    max_entry = max(map(abs, p))\n",
    "    x = p / max_entry\n",
    "    list_max_entries.append(max_entry)\n",
    "    #second and other iterations\n",
    "    while abs(np.linalg.norm(np.dot(A,x)) - np.linalg.norm(max_entry*x)) >= epsilon: \n",
    "        p = np.dot(A,x)\n",
    "        max_entry = max(map(abs, p))\n",
    "        x = p / max_entry\n",
    "        list_max_entries.append(max_entry)\n",
    "    #let's round to integer value both dominant eigenvalue and every entry in corresponding eigenvector\n",
    "    #x = np.round(x)\n",
    "    #max_entry = round(max_entry)\n",
    "    print('Dominant eigenvalue:',max_entry)\n",
    "    print('Corresponding eigenvector:')\n",
    "    print(x/np.linalg.norm(x))\n",
    "    print('')\n",
    "    print('Number of iterations:',len(list_max_entries)-1)\n",
    "    return x/np.linalg.norm(x),max_entry,list_max_entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant eigenvalue: 10.00026293089925\n",
      "Corresponding eigenvector:\n",
      "[-2.47616118e-01 -4.95188291e-01 -3.09512820e-01  1.02532255e-04\n",
      " -4.33350175e-01 -6.18527663e-02 -5.57070348e-01 -2.47498938e-01\n",
      " -1.85675472e-01  4.39380203e-05]\n",
      "\n",
      "Number of iterations: 81\n"
     ]
    }
   ],
   "source": [
    "x, dom_eigenvalue,list_max_entries_A = power_method(A,shape=10,epsilon=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution** We have found dominant eigenvalue (rightly corresponds to the largest value in diagonal matrix D) and corresponding eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Apply the inverse power method to find several (e.g. 4) other eigenvalues and the corresponding eigenvectors. To that end, determine the range in which one should search for the remaining eigenvalues, and then try several random approximations Œª."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose initial x as a vector of all ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.ones(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formula for inverse power method (shifted) is the following (from https://en.wikiversity.org/wiki/Shifted_inverse_iteration).\n",
    "\n",
    "Iterate until $c_k$ converges (diff.between successive approximations is minimal): \n",
    "\n",
    "$\n",
    "B = (A - \\alpha I)^{-1}\n",
    "$\n",
    "\n",
    "$\n",
    "y_{k} = Bx_{k-1}\n",
    "$\n",
    "\n",
    "$\n",
    "c_k = \\frac{y_{k}^T x_{k-1}}{x_{k-1}^T x_{k-1}}\n",
    "$\n",
    "\n",
    "$\n",
    "x_k = \\frac{y_{k}}{\\norm{y_{k}}}\n",
    "$\n",
    "\n",
    ",where first $x_k$ would be initial guess vector and $\\lambda$ would be initial guess eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After convergence of $c_k$ our eigenvalue would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\lambda = \\frac{1}{c_k} + \\alpha\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvector $v$ would be the last $x_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write function for inverse power method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_power_shift(A,guess,x,epsilon=0.0001):\n",
    "    \"\"\"\n",
    "    A is our input matrix\n",
    "    guess is our good guess for eigenvalue\n",
    "    x is our initial x\n",
    "    epsilon to know when to end interation\n",
    "    \"\"\"\n",
    "    a=A-guess*np.identity(A.shape[0])\n",
    "    b=np.linalg.inv(a)\n",
    "    y=np.dot(b,x)\n",
    "    c=(np.dot(y,x))/(np.dot(x,x))\n",
    "    candidates=[c]\n",
    "    c_new = c*2\n",
    "    x = y/np.linalg.norm(y)\n",
    "    eig_vectors = [x]\n",
    "    candidates.append(c_new)\n",
    "    while np.abs(candidates[-1]-candidates[-2])>epsilon:\n",
    "        eig_vectors.append(x)\n",
    "        y=np.dot(b,x)\n",
    "        c=(np.dot(y,x))/(np.dot(x,x))\n",
    "        candidates.append(c)\n",
    "        x = y/np.linalg.norm(y)\n",
    "    return 1/c+guess,eig_vectors[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that eigenvalues of A are 1,2,3,...,10, we will use similar initial guesses in loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approxim.Eigenvalue is: 1.0000000928372466\n",
      "Corresponding.Eigenvector is: [-3.36336678e-01 -4.70870984e-01 -6.72670312e-02  1.21806277e-07\n",
      " -6.72667877e-02 -1.34534671e-01 -2.69068794e-01 -2.01801642e-01\n",
      " -2.69068977e-01 -6.72672930e-01]\n",
      "Approxim.Eigenvalue is: 2.000000028020169\n",
      "Corresponding.Eigenvector is: [1.16503269e-07 3.21633842e-01 2.68028089e-01 1.07211227e-01\n",
      " 4.82450540e-01 4.77308673e-08 4.82450611e-01 3.21633747e-01\n",
      " 3.21633772e-01 3.75239525e-01]\n",
      "Approxim.Eigenvalue is: 3.0000002690810463\n",
      "Corresponding.Eigenvector is: [-1.44004453e-01 -3.84012238e-01 -4.32013662e-01 -1.44004573e-01\n",
      " -4.32013904e-01  4.03466171e-10 -4.80015388e-01 -3.36010754e-01\n",
      " -1.92006300e-01 -2.40007845e-01]\n",
      "Approxim.Eigenvalue is: 4.000000045602787\n",
      "Corresponding.Eigenvector is: [-1.57676376e-01 -4.20470572e-01 -4.20470598e-01 -4.20470810e-01\n",
      "  2.66217395e-07 -2.10235285e-01 -5.25588335e-01 -1.05117709e-01\n",
      " -2.10235338e-01 -2.62794273e-01]\n",
      "Approxim.Eigenvalue is: 5.000000737152379\n",
      "Corresponding.Eigenvector is: [-3.37961377e-01 -4.82805672e-01 -4.34524140e-01 -4.82796768e-02\n",
      " -4.82804721e-01 -2.41401432e-01 -3.86244483e-01  9.32089152e-07\n",
      " -1.44840551e-01  3.02284405e-07]\n",
      "Approxim.Eigenvalue is: 5.99999991619077\n",
      "Corresponding.Eigenvector is: [0.68033579 0.07559332 0.30237168 0.22677864 0.30237186 0.37796453\n",
      " 0.07559308 0.2267787  0.30237156 0.07559303]\n",
      "Approxim.Eigenvalue is: 7.000000596414231\n",
      "Corresponding.Eigenvector is: [0.20459993 0.40919586 0.20459875 0.20459852 0.47739584 0.4091968\n",
      " 0.06819951 0.34099706 0.27279802 0.34099659]\n",
      "Approxim.Eigenvalue is: 8.000000043767427\n",
      "Corresponding.Eigenvector is: [2.40841506e-01 3.37178187e-01 9.23707195e-08 1.44504988e-01\n",
      " 1.44505017e-01 3.85346442e-01 3.37178106e-01 4.33514767e-01\n",
      " 3.85346401e-01 4.33514695e-01]\n",
      "Approxim.Eigenvalue is: 8.999999976221638\n",
      "Corresponding.Eigenvector is: [-0.10894699 -0.38131435 -0.16342046 -0.38131422 -0.10894704 -0.21789386\n",
      " -0.49026129 -0.54473466 -0.21789389 -0.16342038]\n",
      "Approxim.Eigenvalue is: 10.000000030344689\n",
      "Corresponding.Eigenvector is: [-2.47593820e-01 -4.95187570e-01 -3.09492263e-01  1.63995666e-07\n",
      " -4.33289220e-01 -6.18983728e-02 -5.57085990e-01 -2.47593633e-01\n",
      " -1.85695306e-01  7.04304346e-08]\n"
     ]
    }
   ],
   "source": [
    "for guess in [1.1,1.9,2.8,4.1,5.2,6.1,6.8,7.9,9.1,10.1]:\n",
    "    ev,eigvect = inv_power_shift(A,guess,x,epsilon=0.0001)\n",
    "    print('Approxim.Eigenvalue is:',ev)\n",
    "    print('Corresponding.Eigenvector is:',eigvect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "As we see, inverse power method worked well in approximating true eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) With the matrix D of the above problem, form $A = D + uu^T$ with $u$ being a random vector of size 10. Realize the QR algorithm to find the eigenvalues and eigenvectors of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "u = np.random.rand(10, 1)\n",
    "\n",
    "A = D + u.dot(u.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_method(A):\n",
    "    #eigenvectors matrix\n",
    "    EVect = np.eye(len(A))\n",
    "    for i in range(50):\n",
    "        Q, R = np.linalg.qr(A)\n",
    "        A = np.dot(R, Q)\n",
    "        EVect = EVect.dot(Q)\n",
    "    return np.diag(A), EVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues from QR method in 50 iterations are: \n",
      "[10.7552765   9.5773636   8.61778455  7.54808565  6.10341375  5.30631735\n",
      "  4.15167321  3.02999974  2.06280537  1.2822314 ]\n",
      "\n",
      "Eigenvectors from QR method in 50 iterations are: \n",
      "[[ 0.09989687  0.05848652  0.04964943  0.04379501  0.03525637 -0.06126254\n",
      "  -0.05853951 -0.04507244 -0.14146833 -0.97557628]\n",
      " [ 0.04573034  0.02720473  0.02348747  0.02123949  0.01808999 -0.032825\n",
      "  -0.03522761 -0.036496   -0.98353966  0.15760056]\n",
      " [ 0.04093081  0.02485292  0.02194447  0.0205458   0.01911048 -0.03738878\n",
      "  -0.05217555 -0.9934091   0.05225439  0.05220854]\n",
      " [ 0.11420241  0.07125283  0.06491886  0.0640273   0.06986304 -0.16105366\n",
      "  -0.96279115  0.07466565  0.06143805  0.08019583]\n",
      " [ 0.1749375   0.11335604  0.10823911  0.11641797  0.19930808 -0.91114862\n",
      "   0.224525    0.04797929  0.05287987  0.0765058 ]\n",
      " [ 0.12452009  0.08536929  0.08813074  0.11305672  0.93290366  0.28376669\n",
      "   0.06066035  0.01871544  0.02319924  0.03545501]\n",
      " [ 0.36554347  0.27516019  0.33270531  0.73931954 -0.26964663  0.21179159\n",
      "   0.09122996  0.03245492  0.04288401  0.06781139]\n",
      " [ 0.34797678  0.31609747  0.59925919 -0.63094855 -0.08983204  0.09445801\n",
      "   0.04714694  0.01810225  0.02490075  0.04030159]\n",
      " [ 0.3840313   0.5901395  -0.69334194 -0.13343548 -0.04160647  0.04860709\n",
      "   0.02628001  0.01058316  0.01496617  0.02463522]\n",
      " [ 0.72450917 -0.66791595 -0.14925507 -0.06542027 -0.02530884  0.03126067\n",
      "   0.01776287  0.00739077  0.01066499  0.01778179]]\n"
     ]
    }
   ],
   "source": [
    "eigvals,eigvects = QR_method(A)\n",
    "print(\"Eigenvalues from QR method in 50 iterations are: \")\n",
    "print(eigvals)\n",
    "print('')\n",
    "print(\"Eigenvectors from QR method in 50 iterations are: \")\n",
    "print(eigvects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Then apply the power method to find the dominating eigenvalue and the corresponding eigenvector and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom function from Problem 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant eigenvalue: 10.755346233060076\n",
      "Corresponding eigenvector:\n",
      "[0.09979694 0.04568386 0.04088836 0.11408071 0.17474394 0.12437438\n",
      " 0.36507425 0.34743959 0.38301455 0.7256509 ]\n",
      "\n",
      "Number of iterations: 79\n"
     ]
    }
   ],
   "source": [
    "x, dom_eigenvalue,list_max_entries_A = power_method(A,shape=10,epsilon=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "As we see, results from two methods for dominant eigenvalue/eigenvector are pretty similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Solve Ax=b of Problem 1 by Conjugate gradient method: identify the conjugate gradients and the iteration steps? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}2&-1&0\\\\ -1&2&-1\\\\ 0&-1&2\\end{pmatrix};\n",
    "b =\n",
    "\\begin{pmatrix}1\\\\ 0\\\\ 1\\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCM procedure is the next:\n",
    "\n",
    "Step 1. Choose $x_0$ and $\\epsilon$. Set $p_0=r_0=b-Ax_0$.\n",
    "\n",
    "Step 2. For i = 0,1,2,3..do:\n",
    "$$\n",
    "w = Ap_i;\\\\\n",
    "a_i = \\frac{| r_i |^{2}}{p_i^Tw}\\\\\n",
    "x_{i+1} = x_i +a_i p_i\\\\\n",
    "r_{i+1} = r_i - a_i w.\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "|r_{i+1}|^{2} >= \\epsilon\n",
    "\\rightarrow\n",
    "\\\\\n",
    "\\rightarrow\n",
    "\\beta = \\frac{|r_{i+1}|^{2}}{|r_{i}|^{2}}\\\\\n",
    "p_{i+1} = r_{i+1} + \\beta p_i.\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2,-1,0],[-1,2,-1],[0,-1,2]])\n",
    "b = np.array([1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GCM(A,b,stopping_criteria=0.001):\n",
    "    #setting down base accuracy and initial x_0 and p_0=r_0=b-Ax_0\n",
    "    acc=10\n",
    "    x = np.zeros(3)\n",
    "    p = np.subtract(b,np.dot(A,x))\n",
    "    list_conjugates = []\n",
    "    list_conjugates.append(p)\n",
    "    #create list to save number of x vectors\n",
    "    list_1 = []\n",
    "    #iteration\n",
    "    while acc>=stopping_criteria:\n",
    "        w = np.dot(A,p)\n",
    "        a = np.dot(p,p) / np.dot(p,w)\n",
    "        x = x+a*p\n",
    "        list_1.append(x)\n",
    "        r = p - a*w  \n",
    "        beta = np.dot(r,r) / np.dot(p,p)\n",
    "        list_conjugates.append(p)\n",
    "        p = r + beta*p\n",
    "        acc = np.dot(r,r)\n",
    "    num_iter = (len(list_1))\n",
    "    print('Solution vector is', x)\n",
    "    print('Number of iterations is',num_iter)\n",
    "    print('List of conjugate vectors p is saved in list_conjugates' )\n",
    "    return x,num_iter,list_conjugates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vector is [4.88121368 5.85745642 4.88121368]\n",
      "Number of iterations is 26\n",
      "List of conjugate vectors p is saved in list_conjugates\n"
     ]
    }
   ],
   "source": [
    "x,num_iter,list_conjugates = GCM(A,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Solve Ax=b of Problem 2 by Conjugate gradient method (ùõº=1): identify the conjugate gradients and the iteration steps? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "b = u =\n",
    "\\begin{pmatrix}1\\\\ -1\\\\ 1\\end{pmatrix}\\\\\n",
    "uu^T = \n",
    "\\begin{pmatrix}1&-1&1\\\\ -1&1&-1\\\\ 1&-1&1\\end{pmatrix}\\\\\n",
    "A=\n",
    "\\begin{pmatrix}Œ±+1&-1&1\\\\ -1&Œ±+1&-1\\\\ 1&-1&Œ±+1\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([1,-1,1])\n",
    "uuT = np.outer(b,b)\n",
    "b = u\n",
    "alpha_times_identity = np.array([[1,0,0],[0,1,0],[0,0,1]])\n",
    "A = np.add(alpha_times_identity,uuT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution vector is [ 0.39359666 -1.31639244  0.39359666]\n",
      "Number of iterations is 5\n",
      "List of conjugate vectors p is saved in list_conjugates\n"
     ]
    }
   ],
   "source": [
    "x,num_iter,list_conjugates = GCM(A,b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
